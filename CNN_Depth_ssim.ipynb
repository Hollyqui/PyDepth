{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Depth.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgPrHdjxF4Qw",
        "colab_type": "code",
        "outputId": "a6a83ab7-42f6-40a3-e518-e5cd5d6f53fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# !pip uninstall pytorch_ssim\n",
        "!pip install pytorch_ssim"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_ssim in /usr/local/lib/python3.6/dist-packages (0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7iYBUrTOQ9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data as utils\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import timeit\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn import preprocessing\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "import pytorch_ssim\n",
        "height = int(480/2)\n",
        "width = int(640/2)\n",
        "\n",
        "'''Creates Random tensor that is the same size as the image (for testing)'''\n",
        "def imageBatch(nb_image):\n",
        "    imgBatch = torch.rand(nb_image, 3, width, height)\n",
        "    return imgBatch\n",
        "\n",
        "'''Creates Random tensor that is the same size as the depthmap (for testing)'''\n",
        "def depthBatch(nb_image):\n",
        "    depthBatch = torch.rand(nb_image, width*height, 1, 1)\n",
        "    return depthBatch\n",
        "\n",
        "def normalize(imageBatch):\n",
        "    for i in range(len(imageBatch)):\n",
        "      imageBatch[i] = preprocessing.normalize(imageBatch[i], norm='l2', axis=1, copy=True, return_norm=False)\n",
        "    return imageBatch\n",
        "\n",
        "'''CNN doing the first stage of the Semi-Siamese Network (forms the two 'heads')'''\n",
        "def firstStageCNN():\n",
        "    return nn.Sequential(nn.Conv2d(3, 32, kernel_size=3, stride=2),  # optional: add stride\n",
        "                         nn.ReLU(inplace=True),\n",
        "                         nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1),\n",
        "\n",
        "                         nn.Conv2d(32, 62, kernel_size=3, stride=2),\n",
        "                         nn.ReLU(inplace=True),\n",
        "                         nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1),\n",
        "                         nn.MaxPool2d(kernel_size=3),  # optional: add stride\n",
        "                         nn.ReLU(inplace=True),\n",
        "\n",
        "                         nn.Conv2d(62, 92, kernel_size=3, stride=2),  # optional: add stride\n",
        "                         nn.ReLU(inplace=True),\n",
        "                         nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1),\n",
        "\n",
        "                         nn.MaxPool2d(kernel_size=3),  # optional: add stride\n",
        "                         nn.ReLU(inplace=True))\n",
        "\n",
        "'''Form the complete network by taking the two heads and connecting them to\n",
        "the body'''\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        self.cnn1 = firstStageCNN()\n",
        "\n",
        "        self.cnn2 = firstStageCNN()\n",
        "\n",
        "        self.fc = nn.Sequential(nn.Conv2d(2208, 92, kernel_size=1),\n",
        "                                nn.ReLU(inplace=True),\n",
        "\n",
        "                                nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                nn.ReLU(inplace=True),\n",
        "\n",
        "                                nn.Conv2d(92, 62, kernel_size=1),\n",
        "                                nn.ReLU(inplace=True),\n",
        "\n",
        "                                nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                nn.ReLU(inplace=True),\n",
        "\n",
        "                                nn.Conv2d(62, 32, kernel_size=4),\n",
        "                                nn.ReLU(inplace=True),\n",
        "\n",
        "                                nn.Conv2d(32, width*height, kernel_size=1),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Softmax2d()\n",
        "                                )\n",
        "\n",
        "    '''forwards through the first CNNs to the Main body then returns the output'''\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.cnn1(input1)\n",
        "        output2 = self.cnn2(input2)\n",
        "\n",
        "        combined = torch.cat((output1.view(output1.size(0), -1),\n",
        "                              output2.view(output2.size(0), -1)), dim=1)\n",
        "\n",
        "        combined = torch.unsqueeze(combined, 2)\n",
        "        combined = torch.unsqueeze(combined, 3)\n",
        "        out = self.fc(combined)\n",
        "        return out\n",
        "\n",
        "''' Does the training of the whole dataset'''\n",
        "def train(net, training_DATA_LEFT, training_DATA_RIGHT, depthMaps, EPOCHS, BATCH_SIZE):\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
        "    loss_function = pytorch_ssim.SSIM(window_size=int(12))\n",
        "    dataset = utils.TensorDataset(training_DATA_LEFT, training_DATA_RIGHT, depthMaps)\n",
        "    train_dataloader = DataLoader(dataset, shuffle=True, num_workers=0, batch_size=1)\n",
        "    net.zero_grad()\n",
        "    COUNTER = 1\n",
        "    avg_loss = []\n",
        "    print(\"train function was executed\")\n",
        "    for epoch in range(EPOCHS):\n",
        "        for i, data in enumerate(train_dataloader):\n",
        "\n",
        "            img1, img2, depthmap = data\n",
        "            # img1, img2, depthmap = img1.cuda(), img2.cuda(), depthmap.cuda()\n",
        "            optimizer.zero_grad() # reset gradient\n",
        "            outputs = net(img1, img2)\n",
        "            print(outputs.shape)\n",
        "            print(depthmap.shape)\n",
        "            loss = -loss_function(outputs, depthmap)\n",
        "            print(\"Loss:\", loss)\n",
        "            print(\"1-Loss:\", 1-loss)\n",
        "            avg_loss.append(loss.detach())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        #Print out images and epoch numbers \n",
        "        print(\"Epoch number: \", COUNTER)\n",
        "        COUNTER += 1 \n",
        "        avg_loss = np.array(avg_loss)\n",
        "        print(\"Average Loss:\", np.mean(avg_loss))\n",
        "        avg_loss = []\n",
        "        plt.figure()\n",
        "        plt.imshow((outputs.view(height,width)).detach().numpy())\n",
        "        # plt.show()\n",
        "        plt.figure()\n",
        "        plt.imshow((depthmap.view(height,width)).detach().numpy())\n",
        "        # plt.show\n",
        "        image = img1.view(3,height,width)\n",
        "        plt.figure()\n",
        "        plt.imshow(np.swapaxes(np.swapaxes(image.detach().numpy(),0,2),0,1))\n",
        "        plt.show()\n",
        "        outputs = net(img1, img2)\n",
        "        img1 = img1.view(3,height,width)\n",
        "        plt.figure()\n",
        "        plt.imshow((outputs.view(height,width)).detach().numpy())\n",
        "        plt.figure()\n",
        "        plt.imshow((depthmap.view(height,width)).detach().numpy())\n",
        "        plt.figure()\n",
        "        plt.imshow(np.swapaxes(np.swapaxes(img1.detach().numpy(),0,2),0,1))\n",
        "        plt.show()\n",
        "    return net\n",
        "def rescale_img(imageL, imageR, depthMap):\n",
        "  resizedL = []\n",
        "  resizedR = []\n",
        "  resizedDepth = []\n",
        "  for img in imageL:\n",
        "    resizedL.append(rescale(img, (1,0.5,0.5), anti_aliasing=True))\n",
        "  for img in imageR:\n",
        "    resizedR.append(rescale(img, (1,0.5,0.5), anti_aliasing=True))\n",
        "  for img in depthMap:\n",
        "    resizedDepth.append(rescale(img, 0.5, anti_aliasing=True))\n",
        "  return np.array(resizedL), np.array(resizedR), np.array(resizedDepth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIh41BeGQS-w",
        "colab_type": "code",
        "outputId": "fa6fc12d-5740-4634-a8c3-7a73d53b6989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "def main():\n",
        "    height = 480//2\n",
        "    width = 640//2\n",
        "    try: \n",
        "      net = torch.load(\"don't load now\")\n",
        "      net.eval()\n",
        "      print(\"Model loaded successfully\")\n",
        "    except:\n",
        "      net = SiameseNetwork()\n",
        "      # net.cuda()\n",
        "      print(\"New model in training\")\n",
        "    #This will import the real dataset in tensor arrays once the data is available\n",
        "    training_DATA_LEFT = np.load('test_daylight_left.npy')\n",
        "    training_DATA_RIGHT = np.load('test_daylight_right.npy')\n",
        "    depthMaps = np.load('test_depthmap_left.npy')\n",
        "    training_DATA_LEFT, training_DATA_RIGHT, depthMaps = rescale_img(training_DATA_LEFT, training_DATA_RIGHT, depthMaps)\n",
        "    depthMaps = normalize(depthMaps)\n",
        "    # training_DATA_LEFT = np.swapaxes(training_DATA_LEFT,1,3)\n",
        "    # training_DATA_RIGHT = np.swapaxes(training_DATA_RIGHT,1,3)\n",
        "    training_DATA_LEFT = torch.from_numpy(training_DATA_LEFT)\n",
        "    training_DATA_RIGHT = torch.from_numpy(training_DATA_RIGHT)\n",
        "    depthMaps = torch.from_numpy(depthMaps)\n",
        "    # training_DATA_LEFT.cuda()\n",
        "    # training_DATA_RIGHT.cuda()\n",
        "    # depthMaps.cuda()\n",
        "    # reshape output\n",
        "    depthMaps = depthMaps.view(-1,width*height,1,1)\n",
        "    network = final = train(net, training_DATA_LEFT, training_DATA_RIGHT, depthMaps, EPOCHS = 50, BATCH_SIZE = 5)\n",
        "    torch.save(network, 'saved_network')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New model in training\n",
            "train function was executed\n",
            "torch.Size([1, 76800, 1, 1])\n",
            "torch.Size([1, 76800, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-456fbc388a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-456fbc388a3b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# reshape output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdepthMaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepthMaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_DATA_LEFT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_DATA_RIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepthMaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saved_network'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-4c4edcb4571e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, training_DATA_LEFT, training_DATA_RIGHT, depthMaps, EPOCHS, BATCH_SIZE)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepthmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepthmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1-Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_ssim/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img1, img2)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_ssim/__init__.py\u001b[0m in \u001b[0;36m_ssim\u001b[0;34m(img1, img2, window, window_size, channel, size_average)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mmu2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: conv2d(): argument 'padding' must be tuple of ints, not float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0iaAUTJXTxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "~drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JWMLs69Y-PR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiIjCr5uY6l-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/Sample test data/test_daylight_left.npy\" \"test_daylight_left.npy\"\n",
        "!cp \"/content/drive/My Drive/Sample test data/test_daylight_right.npy\" \"test_daylight_right.npy\"\n",
        "!cp \"/content/drive/My Drive/Sample test data/test_depthmap_left.npy\" \"test_depthmap_left.npy\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TzAfxH7F1Q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #This will import the real dataset in tensor arrays once the data is available\n",
        "training_DATA_LEFT = np.load('test_daylight_left.npy')\n",
        "training_DATA_RIGHT = np.load('test_daylight_right.npy')\n",
        "depthMaps = np.load('test_depthmap_left.npy')\n",
        "depthMaps = normalize(depthMaps)\n",
        "# training_DATA_LEFT = np.swapaxes(training_DATA_LEFT,1,3)\n",
        "training_DATA_RIGHT = np.swapaxes(training_DATA_RIGHT,1,3)\n",
        "training_DATA_RIGHT = np.swapaxes(training_DATA_RIGHT,1,2)\n",
        "\n",
        "training_DATA_LEFT = torch.from_numpy(training_DATA_LEFT)\n",
        "training_DATA_RIGHT = torch.from_numpy(training_DATA_RIGHT)\n",
        "depthMaps = torch.from_numpy(depthMaps)\n",
        "\n",
        "print(training_DATA_RIGHT.shape)\n",
        "# reshape output\n",
        "# depthMaps = depthMaps.view(-1,width*height,1,1)\n",
        "plt.figure()\n",
        "plt.imshow((training_DATA_RIGHT[126].detach().numpy()))\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.imshow(depthMaps[126].detach().numpy())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuRD-vmZbUeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}