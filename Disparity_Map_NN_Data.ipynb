{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Disparity_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywOUdx6vQ5SG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data as utils\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import timeit\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imageBatch(nb_image):\n",
        "    imgBatchR_T = torch.randint(0,255,(nb_image,3,9,9))\n",
        "    imgBatchL_T = imgBatchR_T\n",
        "    labelT = torch.ones(nb_image,1)\n",
        "\n",
        "    imgBatchR_F = torch.randint(0,255,(nb_image,3,9,9)) #\n",
        "    imgBatchL_F = torch.randint(0,255,(nb_image,3,9,9))\n",
        "    labelF = torch.zeros(nb_image,1)\n",
        "\n",
        "    finalR = torch.cat((imgBatchR_T,imgBatchR_F))\n",
        "    finalL = torch.cat((imgBatchL_T,imgBatchL_F))\n",
        "    finalLabel = torch.cat((labelT,labelF))\n",
        "\n",
        "    return finalR, finalL, finalLabel\n",
        "\n",
        "def firstStageCNN():\n",
        "    return nn.Sequential(nn.Linear(3*9*9, 50), #L1\n",
        "                         nn.ReLU(inplace=True),\n",
        "                         \n",
        "                         nn.Linear(50, 50), #L2\n",
        "                         nn.ReLU(inplace=True))\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        self.cnn1 = firstStageCNN()\n",
        "        \n",
        "        self.cnn2 = firstStageCNN()\n",
        "\n",
        "        \n",
        "        self.fc = nn.Sequential(nn.Linear(100, 75), #L3\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                \n",
        "                                nn.Linear(75, 50), #L4\n",
        "                                nn.ReLU(inplace=True),\n",
        "                            \n",
        "                                nn.Linear(50, 25), #L5\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                \n",
        "                                nn.Linear(25, 1), #L6\n",
        "                                nn.Sigmoid())\n",
        "    \n",
        "    def forward(self, input1, input2):\n",
        "        \n",
        "        output1 = self.cnn1(input1.float().view(-1,3*9*9))\n",
        "        output2 = self.cnn2(input2.float().view(-1,3*9*9))\n",
        "\n",
        "\n",
        "        combined = torch.cat((output1.view(output1.size(0), -1),\n",
        "                              output2.view(output2.size(0), -1)), dim=1)\n",
        "\n",
        "        combined = torch.unsqueeze(combined,2)\n",
        "        combined = torch.unsqueeze(combined,3)\n",
        "        combined = combined.view(-1,100)\n",
        "        \n",
        "        out = self.fc(combined)\n",
        "        \n",
        "        return out\n",
        "\n",
        "def train(net, finalR, finalL, finalLabel, EPOCHS, BATCH_SIZE):\n",
        "    height, width = 9,9\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
        "    loss_function = nn.BCELoss()\n",
        "    dataset = utils.TensorDataset(finalL, finalR, finalLabel)\n",
        "    train_dataloader = DataLoader(dataset, shuffle=True, num_workers=8, batch_size=6)\n",
        "    COUNTER = 1\n",
        "    net.zero_grad()\n",
        "\n",
        "    print(\"train function was executed\")\n",
        "    for epoch in range(EPOCHS):\n",
        "        avg_loss = 0\n",
        "        for i, data in enumerate(train_dataloader):\n",
        "            img1, img2, depthmap = data\n",
        "            # img1, img2, depthmap = img1.cuda(), img2.cuda(), depthmap.cuda()\n",
        "            optimizer.zero_grad() # reset gradient\n",
        "            outputs = net(img1, img2)\n",
        "            outputs = outputs.cpu()\n",
        "            depthmap = depthmap.cpu()\n",
        "            loss = loss_function(outputs, depthmap)\n",
        "            #print(\"Loss:\", float(loss))\n",
        "            avg_loss+=loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        #Print out images and epoch numbers \n",
        "        print(\"Epoch number: \", COUNTER)\n",
        "        COUNTER += 1 \n",
        "        # avg_loss = np.array(avg_loss)\n",
        "        #print(\"Average Loss:\", avg_loss/i)\n",
        "        # plot_weights(net.cpu(), 0, single_channel = False)\n",
        "        outputs = outputs.cpu()\n",
        "        # img1 = img1.cpu()\n",
        "        # img2 = img2.cpu()\n",
        "        depthmap = depthmap.cpu()\n",
        "        #print(\"Output size\", outputs.size())\n",
        "        #for param in net.parameters():\n",
        "        #    print('average weight per layer: ', np.mean(np.array(param.data.cpu())))\n",
        "        image = np.swapaxes(img1.numpy(), 1,3)\n",
        "        image1 = np.swapaxes(img2.numpy(), 1,3)\n",
        "        plt.figure()\n",
        "        plt.imshow(image[0])\n",
        "        plt.figure()\n",
        "        plt.imshow(image1[0])\n",
        "        plt.show()\n",
        "        print('Likeliness value:', outputs[-1])\n",
        "        print(\"Actual Likeness\", depthmap[-1])\n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_tgPosRgIsc",
        "colab_type": "code",
        "outputId": "b2a3aef8-9b0e-4e28-d913-62104063fca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiE9a-g_gV6m",
        "colab_type": "code",
        "outputId": "ac9c1310-0cdf-498f-cbb5-d4a0f16f6442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks/Image 1\"\n",
        "!cp \"/content/drive/My Drive/Colab Notebooks/Image 1/cropped_noisy_compilation_1.npy\" \"cropped_noisy_compilation_1.npy\"\n",
        "!cp \"/content/drive/My Drive/Colab Notebooks/Image 1/cropped_original_compilation_1.npy\" \"cropped_original_compilation_1.npy\"\n",
        "!cp \"/content/drive/My Drive/Colab Notebooks/Image 1/similarity_rating_compilation_1.npy\" \"similarity_rating_compilation_1.npy\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cropped_noisy_compilation_1.npy      test1.jpg\n",
            "cropped_original_compilation_1.npy   test1_noisy.png\n",
            "similarity_rating_compilation_1.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPKgF2sefTiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NOISY = np.load(\"cropped_noisy_compilation_1.npy\")\n",
        "ORIG = np.load(\"cropped_original_compilation_1.npy\")\n",
        "LABEL = np.load(\"similarity_rating_compilation_1.npy\")\n",
        "\n",
        "\n",
        "# NOISY = np.swapaxes(NOISY, 1,3)\n",
        "# for i in range(50):\n",
        "#   plt.figure()\n",
        "#   plt.imshow(NOISY[i])\n",
        "#   plt.show()\n",
        "# NOISY = np.swapaxes(NOISY, 1,3)\n",
        "\n",
        "\n",
        "NOISY = torch.from_numpy(NOISY).float()\n",
        "ORIG = torch.from_numpy(ORIG).float()\n",
        "LABEL = torch.from_numpy(LABEL).float()\n",
        "\n",
        "net = SiameseNetwork()\n",
        "net#.cuda()\n",
        "NumberIMG = 500\n",
        "EPOCHS = 50\n",
        "\n",
        "#finalR, finalL, finalLabel = imageBatch(NumberIMG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzJEBE685zSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = train(net,NOISY,ORIG,LABEL,EPOCHS,NumberIMG)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}