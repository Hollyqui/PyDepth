{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Depth.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7iYBUrTOQ9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data as utils\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import timeit\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "import kornia\n",
        "height = int(480/2)\n",
        "width = int(640/2)\n",
        "\n",
        "'''Creates Random tensor that is the same size as the image (for testing)'''\n",
        "def imageBatch(nb_image):\n",
        "    imgBatch = torch.rand(nb_image, 3, width, height)\n",
        "    return imgBatch\n",
        "\n",
        "'''Creates Random tensor that is the same size as the depthmap (for testing)'''\n",
        "def depthBatch(nb_image):\n",
        "    depthBatch = torch.rand(nb_image, width*height, 1, 1)\n",
        "    return depthBatch\n",
        "\n",
        "def normalize(imageBatch):\n",
        "    for i in range(len(imageBatch)):\n",
        "      imageBatch[i] = preprocessing.normalize(imageBatch[i], norm='l2', axis=1, copy=True, return_norm=False)\n",
        "    return imageBatch\n",
        "\n",
        "'''CNN doing the first stage of the Semi-Siamese Network (forms the two 'heads')'''\n",
        "def firstStageCNN():\n",
        "    return nn.Sequential(nn.Conv2d(3, 32, kernel_size=3, stride=2),  # optional: add stride\n",
        "                         nn.ReLU(inplace=True),\n",
        "                         nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),\n",
        "\n",
        "                         nn.Conv2d(32, 62, kernel_size=3, stride=2),\n",
        "                         nn.ReLU(inplace=True),\n",
        "                         nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),\n",
        "                         nn.MaxPool2d(kernel_size=3),  # optional: add stride\n",
        "                         nn.ReLU(inplace=True),\n",
        "\n",
        "                         nn.Conv2d(62, 92, kernel_size=3, stride=2),  # optional: add stride\n",
        "                         nn.ReLU(inplace=True),\n",
        "                         nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),\n",
        "\n",
        "                         nn.MaxPool2d(kernel_size=3),  # optional: add stride\n",
        "                         nn.ReLU(inplace=True))\n",
        "\n",
        "'''Form the complete network by taking the two heads and connecting them to\n",
        "the body'''\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        self.cnn1 = firstStageCNN()\n",
        "\n",
        "        self.cnn2 = firstStageCNN()\n",
        "\n",
        "        self.fc = nn.Sequential(nn.Conv2d(2208, 200, kernel_size=1),\n",
        "                                nn.ReLU(inplace=True),\n",
        "\n",
        "                                nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                nn.ReLU(inplace=True),\n",
        "\n",
        "                                nn.Conv2d(200, 300, kernel_size=1),\n",
        "                                nn.ReLU(inplace=True),\n",
        "\n",
        "                                nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                nn.ReLU(inplace=True),\n",
        "\n",
        "                                nn.Conv2d(300, 500, kernel_size=4),\n",
        "                                nn.ReLU(inplace=True),\n",
        "\n",
        "                                nn.Conv2d(500, width*height, kernel_size=1),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Softmax2d()\n",
        "                                )\n",
        "\n",
        "    '''forwards through the first CNNs to the Main body then returns the output'''\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.cnn1(input1)\n",
        "        output2 = self.cnn2(input2)\n",
        "\n",
        "        combined = torch.cat((output1.view(output1.size(0), -1),\n",
        "                              output2.view(output2.size(0), -1)), dim=1)\n",
        "\n",
        "        combined = torch.unsqueeze(combined, 2)\n",
        "        combined = torch.unsqueeze(combined, 3)\n",
        "        out = self.fc(combined)\n",
        "        return out\n",
        "\n",
        "''' Does the training of the whole dataset'''\n",
        "def train(net, training_DATA_LEFT, training_DATA_RIGHT, depthMaps, EPOCHS, BATCH_SIZE):\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
        "    loss_function = kornia.losses.SSIM(11, reduction='mean')\n",
        "    dataset = utils.TensorDataset(training_DATA_LEFT, training_DATA_RIGHT, depthMaps)\n",
        "    train_dataloader = DataLoader(dataset, shuffle=True, num_workers=8, batch_size=6)\n",
        "    COUNTER = 1\n",
        "    print(\"train function was executed\")\n",
        "    for epoch in range(EPOCHS):\n",
        "        avg_loss = 0\n",
        "        for i, data in enumerate(train_dataloader):\n",
        "            net.zero_grad()\n",
        "            img1, img2, depthmap = data\n",
        "            img1, img2, depthmap = img1.cuda(), img2.cuda(), depthmap.cuda()\n",
        "            optimizer.zero_grad() # reset gradient\n",
        "            outputs = net(img1, img2)\n",
        "            loss = loss_function(outputs, depthmap)\n",
        "            print(\"Loss:\", float(loss))\n",
        "            avg_loss+=loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        #Print out images and epoch numbers \n",
        "        print(\"Epoch number: \", COUNTER)\n",
        "        COUNTER += 1 \n",
        "        # avg_loss = np.array(avg_loss)\n",
        "        print(\"Average Loss:\", avg_loss/i)\n",
        "        outputs = outputs.cpu()\n",
        "        img1 = img1.cpu()\n",
        "        img2 = img2.cpu()\n",
        "        depthmap = depthmap.cpu()\n",
        "        outputs.size\n",
        "        print(\"Output size\", outputs.size())\n",
        "        plt.figure()\n",
        "        plt.imshow((outputs[0].view(height,width)).detach().numpy())\n",
        "        # plt.show()\n",
        "        plt.figure()\n",
        "        plt.imshow((depthmap[0].view(height,width)).detach().numpy())\n",
        "        # plt.show\n",
        "        image = img1[0].view(3,height,width)\n",
        "        plt.figure()\n",
        "        plt.imshow(np.swapaxes(np.swapaxes(image.detach().numpy(),0,2),0,1))\n",
        "        plt.show()\n",
        "    return net\n",
        "def rescale_img(imageL, imageR, depthMap):\n",
        "  resizedL = []\n",
        "  resizedR = []\n",
        "  resizedDepth = []\n",
        "  for img in imageL:\n",
        "    resizedL.append(rescale(img, (1,0.5,0.5), anti_aliasing=True))\n",
        "  for img in imageR:\n",
        "    resizedR.append(rescale(img, (1,0.5,0.5), anti_aliasing=True))\n",
        "  for img in depthMap:\n",
        "    resizedDepth.append(rescale(img, 0.5, anti_aliasing=True))\n",
        "  return np.array(resizedL), np.array(resizedR), np.array(resizedDepth)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CK5PI10F6JtA",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    height = 240\n",
        "    width = 320\n",
        "    net = SiameseNetwork()\n",
        "    net.cuda()\n",
        "    #This will import the real dataset in tensor arrays once the data is available\n",
        "    training_DATA_LEFT = np.load('test_daylight_left.npy')\n",
        "    training_DATA_RIGHT = np.load('test_daylight_right.npy')\n",
        "    depthMaps = np.load('test_depthmap_left.npy')\n",
        "    # training_DATA_LEFT = np.swapaxes(training_DATA_LEFT,1,3)\n",
        "    # training_DATA_RIGHT = np.swapaxes(training_DATA_RIGHT,1,3)\n",
        "    training_DATA_LEFT, training_DATA_RIGHT, depthMaps = rescale_img(training_DATA_LEFT, training_DATA_RIGHT, depthMaps)\n",
        "    depthMaps = normalize(depthMaps)\n",
        "\n",
        "    training_DATA_LEFT = torch.from_numpy(training_DATA_LEFT)\n",
        "    training_DATA_RIGHT = torch.from_numpy(training_DATA_RIGHT)\n",
        "    depthMaps = torch.from_numpy(depthMaps)\n",
        "    # reshape output\n",
        "    depthMaps = depthMaps.view(-1,int(width*height),1,1)\n",
        "    print(\"starting training\")\n",
        "    network = final = train(net, training_DATA_LEFT, training_DATA_RIGHT, depthMaps, EPOCHS = 150, BATCH_SIZE = 5)\n",
        "    torch.save(network, 'saved_network')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0iaAUTJXTxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "!pip install kornia\n",
        "~drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JWMLs69Y-PR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiIjCr5uY6l-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/Sample test data/test_daylight_left.npy\" \"test_daylight_left.npy\"\n",
        "!cp \"/content/drive/My Drive/Sample test data/test_daylight_right.npy\" \"test_daylight_right.npy\"\n",
        "!cp \"/content/drive/My Drive/Sample test data/test_depthmap_left.npy\" \"test_depthmap_left.npy\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}