{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Disparity_Map_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_tgPosRgIsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiE9a-g_gV6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/drive/My Drive/Data Alica method less noisy new/Image 1/\"\n",
        "\n",
        "!for i in {1..10}; do cp \"/content/drive/My Drive/Data Alica method less noisy new/Image $i/cropped_noisy_compilation_$i.npy\" \"Noi$i.npy\"; done\n",
        "!for i in {1..10}; do cp \"/content/drive/My Drive/Data Alica method less noisy new/Image $i/cropped_original_compilation_$i.npy\" \"Ori$i.npy\"; done\n",
        "!for i in {1..10}; do cp \"/content/drive/My Drive/Data Alica method less noisy new/Image $i/similarity_rating_compilation_$i.npy\" \"Label$i.npy\"; done"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywOUdx6vQ5SG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data as utils\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import timeit\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imageBatch(nb_image):\n",
        "    imgBatchR_T = torch.randint(0,255,(nb_image,3,9,9))\n",
        "    imgBatchL_T = imgBatchR_T\n",
        "    labelT = torch.ones(nb_image,1)\n",
        "\n",
        "    imgBatchR_F = torch.randint(0,255,(nb_image,3,9,9)) #\n",
        "    imgBatchL_F = torch.randint(0,255,(nb_image,3,9,9))\n",
        "    labelF = torch.zeros(nb_image,1)\n",
        "\n",
        "    finalR = torch.cat((imgBatchR_T,imgBatchR_F))\n",
        "    finalL = torch.cat((imgBatchL_T,imgBatchL_F))\n",
        "    finalLabel = torch.cat((labelT,labelF))\n",
        "\n",
        "    return finalR, finalL, finalLabel\n",
        "\n",
        "class Flatten(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size()[0], -1)\n",
        "\n",
        "def firstStageCNN():\n",
        "    return nn.Sequential(nn.Linear(3*9*9, 50), #L1\n",
        "                         nn.ReLU(inplace=True),\n",
        "                         \n",
        "                         nn.Linear(50, 50), #L2\n",
        "                         nn.ReLU(inplace=True))\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        self.cnn1 = firstStageCNN()\n",
        "        \n",
        "        self.cnn2 = firstStageCNN()\n",
        "\n",
        "        \n",
        "        self.fc = nn.Sequential(nn.Linear(100, 75), #L3\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                \n",
        "                                nn.Linear(75, 50), #L4\n",
        "                                nn.ReLU(inplace=True),\n",
        "                            \n",
        "                                nn.Linear(50, 25), #L5\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                \n",
        "                                nn.Linear(25, 1), #L6\n",
        "                                nn.Sigmoid())\n",
        "    \n",
        "    def forward(self, input1, input2):\n",
        "        \n",
        "        output1 = self.cnn1(input1.float().view(-1,3*9*9))\n",
        "        output2 = self.cnn2(input2.float().view(-1,3*9*9))\n",
        "\n",
        "\n",
        "        combined = torch.cat((output1.view(output1.size(0), -1),\n",
        "                              output2.view(output2.size(0), -1)), dim=1)\n",
        "\n",
        "        combined = torch.unsqueeze(combined,2)\n",
        "        combined = torch.unsqueeze(combined,3)\n",
        "        combined = combined.view(-1,100)\n",
        "        \n",
        "        out = self.fc(combined)\n",
        "        \n",
        "        return out\n",
        "\n",
        "def train(net, finalR, finalL, finalLabel, EPOCHS, BATCH_SIZE):\n",
        "    height, width = 9,9\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
        "    loss_function = nn.BCELoss()\n",
        "    dataset = utils.TensorDataset(finalL, finalR, finalLabel)\n",
        "    train_dataloader = DataLoader(dataset, shuffle=True, num_workers=8, batch_size=BATCH_SIZE)\n",
        "    COUNTER = 1\n",
        "    net.zero_grad()\n",
        "\n",
        "    print(\"train function was executed\")\n",
        "    for epoch in range(EPOCHS):\n",
        "        avg_loss = 0\n",
        "        for i, data in enumerate(train_dataloader):\n",
        "            img1, img2, depthmap = data\n",
        "            # img1, img2, depthmap = img1.cuda(), img2.cuda(), depthmap.cuda()\n",
        "            optimizer.zero_grad() # reset gradient\n",
        "            outputs = net(img1, img2)\n",
        "            outputs = outputs.cpu()\n",
        "            depthmap = depthmap.cpu()\n",
        "            loss = loss_function(outputs, depthmap)\n",
        "            #print(\"Loss:\", float(loss))\n",
        "            avg_loss+=loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        #Print out images and epoch numbers \n",
        "        print(\"Epoch number: \", COUNTER)\n",
        "        COUNTER += 1 \n",
        "        print(\"Average Loss:\", avg_loss/i)\n",
        "        outputs = outputs.cpu()\n",
        "        # img1 = img1.cpu()\n",
        "        # img2 = img2.cpu()\n",
        "        depthmap = depthmap.cpu()\n",
        "\n",
        "        # image = np.swapaxes(img1.numpy(), 1,3)\n",
        "        # image1 = np.swapaxes(img2.numpy(), 1,3)\n",
        "        # plt.figure()\n",
        "        # plt.imshow(image[0].astype('uint8'))\n",
        "        # plt.figure()\n",
        "        # plt.imshow(image1[0].astype('uint8'))\n",
        "        # plt.show()\n",
        "        print('Likeliness value:', outputs[-1])\n",
        "        print(\"Actual Likeness\", depthmap[-1])\n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPKgF2sefTiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NOISY, ORIG, LABEL = [],[],[] \n",
        "for i in range(10):\n",
        "  NOISY.append(np.load(\"Noi\"+str(i+1)+\".npy\"))\n",
        "  ORIG.append(np.load(\"Ori\"+str(i+1)+\".npy\"))\n",
        "  LABEL.append(np.load(\"Label\"+str(i+1)+\".npy\"))\n",
        "\n",
        "NOISY = np.concatenate(tuple(NOISY))\n",
        "ORIG = np.concatenate(tuple(ORIG))\n",
        "LABEL = np.concatenate(tuple(LABEL)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUXdZ5uh7gSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NOISY = torch.from_numpy(NOISY).float()\n",
        "ORIG = torch.from_numpy(ORIG).float()\n",
        "LABEL = torch.from_numpy(LABEL).float()\n",
        "\n",
        "net = SiameseNetwork()\n",
        "batch_size = 10\n",
        "EPOCHS = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzJEBE685zSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = train(net,ORIG,NOISY,LABEL,EPOCHS,batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZRKq6Trln4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the model\n",
        "from google.colab import files\n",
        "torch.save(final, \"disparity_NN.pth\")\n",
        "files.download(\"disparity_NN.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}